{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i6cLMcoQDvC"
   },
   "source": [
    "#### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dF_-eBk0dYqY",
    "outputId": "2199424a-cd6d-48c2-b92e-990729d9fa8c"
   },
   "outputs": [],
   "source": [
    "# !pip3 install mediapipe\n",
    "!curl --output model.task \"https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwQNhgq0PvkQ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iPl9L3UQNRZ"
   },
   "outputs": [],
   "source": [
    "project_path = \"drive/MyDrive/NTU_IOT_final\"\n",
    "picture_path = os.path.join(project_path, \"pic\")\n",
    "video_path = os.path.join(project_path, \"video\")\n",
    "output_path = os.path.join(project_path, \"output\")\n",
    "model_path = \"model.task\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbOfwFSAQrmK"
   },
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3wSF3qXQtt4"
   },
   "outputs": [],
   "source": [
    "def get_frame_from_photo(path):\n",
    "    frame = cv2.imread(path)\n",
    "    if frame is None:\n",
    "        print(\"get_frame_from_photo() failed\")\n",
    "    return frame\n",
    "\n",
    "def get_frame_frome_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"get_frame_from_video() failed\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"width: {width}, height: {height}, fps: {fps}\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        timestamp_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        yield frame, timestamp_ms\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "def process_frame(frame):\n",
    "    try:\n",
    "        show_frame(frame)\n",
    "        frame = frame.copy()\n",
    "        processed_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        processed_frame = cv2.GaussianBlur(processed_frame, (5, 5), 0)\n",
    "        processed_frame = cv2.normalize(processed_frame, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        show_frame(processed_frame, \"gray\")\n",
    "        return processed_frame\n",
    "    except:\n",
    "        print(\"process_frame() failed\")\n",
    "        return frame\n",
    "\n",
    "def show_frame(frame, cmap=None):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(frame, cmap=cmap)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def mark_cross(frame, x, y, size=8, color=(255, 0, 0), thickness=2):\n",
    "    cv2.line(frame, (x - size, y - size), (x + size, y + size), color, thickness)\n",
    "    cv2.line(frame, (x - size, y + size), (x + size, y - size), color, thickness)\n",
    "    return frame\n",
    "\n",
    "def add_text(frame, text, x, y, font_scale=0.8, color=(255, 0, 0), thickness=2):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, text, (x, y), font, font_scale, color, thickness)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcQZWf__QgsT"
   },
   "source": [
    "#### Crop Keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P74WdAmrQo8C"
   },
   "outputs": [],
   "source": [
    "def crop_keyboard(frame, n_scanlines=100, white_threshold=200, min_transactions=35, min_white_ratio=0.3):\n",
    "    processed_frame = process_frame(frame)\n",
    "\n",
    "    height, width = processed_frame.shape\n",
    "    scanline_positions = np.linspace(0, height - 1, n_scanlines).astype(int)\n",
    "    key_areas = []\n",
    "\n",
    "    for y in scanline_positions:\n",
    "        scanline = processed_frame[y, :]\n",
    "\n",
    "        binary_line = (scanline > white_threshold).astype(int)\n",
    "        diff = np.abs(np.diff(binary_line))\n",
    "        transitions = np.sum(diff)\n",
    "        white_ratio = np.sum(binary_line) / width\n",
    "\n",
    "        if transitions > min_transactions and white_ratio > min_white_ratio:\n",
    "            key_areas.append(y)\n",
    "\n",
    "    if key_areas:\n",
    "        top = max(0, min(key_areas) + int(height * 1 / n_scanlines))\n",
    "        bottom = min(height, max(key_areas) - int(height * 1 / n_scanlines))\n",
    "        return frame[top:bottom, :], top, bottom\n",
    "    else:\n",
    "        print(\"keyboard not found\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vDTgKPD9RXu2",
    "outputId": "e52855af-0414-4fd4-cf80-f7b73620e810"
   },
   "outputs": [],
   "source": [
    "show = True\n",
    "keyboards = []\n",
    "\n",
    "for filename in os.listdir(picture_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        path = os.path.join(picture_path, filename)\n",
    "        frame = get_frame_from_photo(path)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        keyboard, _, _ = crop_keyboard(frame)\n",
    "        keyboard = cv2.resize(keyboard, (int(keyboard.shape[1] * 256 / keyboard.shape[0]), 256))\n",
    "        keyboards.append(keyboard)\n",
    "        if show:\n",
    "            print(f\"original frame: {path}\")\n",
    "            show_frame(frame)\n",
    "            print(f\"crop frame: {path}\")\n",
    "            show_frame(keyboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kPOLfWEVxCT"
   },
   "source": [
    "#### Label Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCoUU23GV8bJ"
   },
   "outputs": [],
   "source": [
    "def show_grayscale_distr(gray_frame):\n",
    "    hist = cv2.calcHist([gray_frame], [0], None, [256], [0, 256])\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title(\"Grayscale Distribution\")\n",
    "    plt.plot(hist, color=\"black\")\n",
    "    plt.xlabel(\"Gray Level\")\n",
    "    plt.ylabel(\"Pixel Count\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "def get_key_contour(frame, kernel_size=5, kx=20, ky=2, crop=5, threshold=5000):\n",
    "    b_channel, g_channel, r_channel = cv2.split(frame)\n",
    "    frame_mn_gray = np.minimum(np.minimum(b_channel, g_channel), r_channel)\n",
    "\n",
    "    sobelx = cv2.Sobel(frame_mn_gray, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobely = cv2.Sobel(frame_mn_gray, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    sobel = np.sqrt(kx * sobelx ** 2 + ky * sobely ** 2)\n",
    "\n",
    "    contour = np.zeros_like(sobel, dtype=np.uint8)\n",
    "    contour[sobel <= threshold] = 255\n",
    "    contour[sobel > threshold] = 0\n",
    "    contour[:crop, :] = 0\n",
    "    contour[-crop:, :] = 0\n",
    "    contour[:, :crop] = 0\n",
    "    contour[:, -crop:] = 0\n",
    "\n",
    "    return contour\n",
    "\n",
    "def get_white_key_component(frame, min_area=2000, max_area=12000, min_height=220, max_width=120):\n",
    "    n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(frame)\n",
    "\n",
    "    avg_centorid = np.mean(centroids[1:, 1])\n",
    "    for i in range(1, n_labels):\n",
    "        if abs(avg_centorid - centroids[i, 1]) > 30 or stats[i, 4] < min_area or stats[i, 4] > max_area or stats[i, 2] > max_width or stats[i, 3] < min_height:\n",
    "            labels[labels == i] = 0\n",
    "\n",
    "    labels[labels > 0] = 255\n",
    "    labels = labels.astype(np.uint8)\n",
    "    n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(labels)\n",
    "    labels = labels.astype(np.uint8)\n",
    "\n",
    "    return n_labels, labels, stats, centroids\n",
    "\n",
    "def get_black_key_component(frame, min_width=30, max_width=90, max_height=220):\n",
    "    height, width = frame.shape\n",
    "    new_frame = np.zeros_like(frame)\n",
    "    for x in range(height):\n",
    "        start_idx = -1\n",
    "        for y in range(width):\n",
    "            if frame[x, y] == 0:\n",
    "                if start_idx == -1:\n",
    "                    start_idx = y\n",
    "            else:\n",
    "                if start_idx != -1:\n",
    "                    length = y - start_idx\n",
    "                    if min_width <= length and length <= max_width:\n",
    "                        new_frame[x, start_idx:y] = 255\n",
    "                    start_idx = -1\n",
    "\n",
    "        if start_idx != -1:\n",
    "            length = width - start_idx\n",
    "            if length <= max_width:\n",
    "                new_frame[x, start_idx:width] = 255\n",
    "\n",
    "    n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(new_frame)\n",
    "    avg_centorid = np.mean(centroids[1:, 1])\n",
    "    for i in range(1, n_labels):\n",
    "        if abs(avg_centorid - centroids[i, 1]) > 30 or i in labels and np.argwhere(labels == i)[:, 0].max() > max_height:\n",
    "            labels[labels == i] = 0\n",
    "\n",
    "    labels[labels > 0] = 255\n",
    "    show_frame(labels, \"gray\")\n",
    "    labels = labels.astype(np.uint8)\n",
    "    n_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(labels)\n",
    "    labels = labels.astype(np.uint8)\n",
    "\n",
    "    return n_labels, labels, stats, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q6i7-ASUaaId",
    "outputId": "5dbd9955-8a23-4482-d3de-fd64e550e61b"
   },
   "outputs": [],
   "source": [
    "show = True\n",
    "\n",
    "for keyboard in keyboards:\n",
    "    contour = get_key_contour(keyboard)\n",
    "    n_labels1, labels1, stats1, centroids1 = get_white_key_component(contour)\n",
    "    n_labels2, labels2, stats2, centroids2 = get_black_key_component(labels1)\n",
    "\n",
    "    labels2_offset = labels2 + n_labels1 - 1\n",
    "    labels2_offset[labels2_offset == n_labels1] = 0\n",
    "\n",
    "    labels = labels1 + (labels2 + n_labels1)\n",
    "    n_labels = n_labels1 + n_labels2 - 1\n",
    "    stats = np.concatenate((stats1, stats2[1:]), axis=0)\n",
    "    centroids = np.concatenate((centroids1, centroids2[1:]), axis=0)\n",
    "\n",
    "    order = centroids[1:, 0].argsort() + 1\n",
    "\n",
    "    if show:\n",
    "        show_frame(contour, \"gray\")\n",
    "\n",
    "        print(f\"number of keys: {n_labels - 1}\")\n",
    "        show_labels = cv2.cvtColor(labels.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "        show_labels[labels1 > 0] = 255\n",
    "        for idx, i in enumerate(order):\n",
    "            color = (255, 0, 0)\n",
    "            if i >= n_labels1:\n",
    "                color = (0, 255, 0)\n",
    "            show_labels = mark_cross(show_labels, int(centroids[i][0]), int(centroids[i][1]), color=color)\n",
    "            show_labels = add_text(show_labels, f\"{idx}\", int(centroids[i][0]) - 10, int(centroids[i][1] + 40), color=color)\n",
    "\n",
    "        show_frame(show_labels, \"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO9rIOpQge96"
   },
   "source": [
    "#### Hand Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gU_OAPtcgi1n"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"model.task\"),\n",
    "    running_mode=VisionRunningMode.VIDEO\n",
    ")\n",
    "\n",
    "def draw_landmarks_on_image(frame, hand_landmarks, line_color=(0, 255, 0), circle_color=(255, 0, 0)):\n",
    "    HAND_CONNECTIONS = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "        (0, 5), (5, 6), (6, 7), (7, 8),\n",
    "        (0, 9), (9, 10), (10, 11), (11, 12),\n",
    "        (0, 13), (13, 14), (14, 15), (15, 16),\n",
    "        (0, 17), (17, 18), (18, 19), (19, 20)\n",
    "    ]\n",
    "\n",
    "    frame = frame.copy()\n",
    "    height, width, _ = frame.shape\n",
    "    for landmarks in hand_landmarks:\n",
    "        for start_idx, end_idx in HAND_CONNECTIONS:\n",
    "            x1, y1 = int(landmarks[start_idx].x * width), int(landmarks[start_idx].y * height)\n",
    "            x2, y2 = int(landmarks[end_idx].x * width), int(landmarks[end_idx].y * height)\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), line_color, 3)\n",
    "        for idx, landmark in enumerate(landmarks):\n",
    "            x = int(landmark.x * width)\n",
    "            y = int(landmark.y * height)\n",
    "            cv2.circle(frame, (x, y), 5, circle_color, -1)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def get_difference_mask(frame1, frame2, threshold=30):\n",
    "    b_channel, g_channel, r_channel = cv2.split(frame1)\n",
    "    frame1_mn_gray = np.minimum(np.minimum(b_channel, g_channel), r_channel)\n",
    "    b_channel, g_channel, r_channel = cv2.split(frame2)\n",
    "    frame2_mn_gray = np.minimum(np.minimum(b_channel, g_channel), r_channel)\n",
    "\n",
    "    diff = np.abs(frame1_mn_gray.astype(np.int32) - frame2_mn_gray.astype(np.int32)).astype(np.uint8)\n",
    "    diff[diff < threshold] = 0\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guoSj6ZTsbE2"
   },
   "source": [
    "#### Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fXT3BmLrsZ6N",
    "outputId": "8517ac7e-6ee1-40b1-9c11-5332fb12530a"
   },
   "outputs": [],
   "source": [
    "show = True\n",
    "saved = False\n",
    "\n",
    "\n",
    "for filename in os.listdir(video_path):\n",
    "    if filename.endswith(\"33.mp4\"):\n",
    "        path = os.path.join(video_path, filename)\n",
    "        landmarker = HandLandmarker.create_from_options(options)\n",
    "\n",
    "        if saved:\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"fail to open {path} video\")\n",
    "                continue\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            print(f\"width: {width}, height: {height}, fps: {fps}\")\n",
    "            cap.release()\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "            out = cv2.VideoWriter(f\"{output_path}/test.mp4\", fourcc, fps, (width, height))\n",
    "\n",
    "        keyboard_info = None\n",
    "        first_frame = None\n",
    "        for frame, timestamp in get_frame_frome_video(path):\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            if first_frame is None:\n",
    "                first_frame = frame.copy()\n",
    "\n",
    "            if not keyboard_info:\n",
    "                keyboard, top, bottom = crop_keyboard(frame, white_threshold=180, min_transactions=10, min_white_ratio=0.3)\n",
    "                # if bottom - top + 1 > 256:\n",
    "                #     keyboard = cv2.resize(keyboard, (int(keyboard.shape[1] * 256 / keyboard.shape[0]), 256))\n",
    "\n",
    "                contour = get_key_contour(keyboard, kx=30, ky=3)\n",
    "                show_frame(contour, \"gray\")\n",
    "\n",
    "                n_labels1, labels1, stats1, centroids1 = get_white_key_component(contour, min_area=3000, max_area=14000)\n",
    "                n_labels2, labels2, stats2, centroids2 = get_black_key_component(labels1)\n",
    "\n",
    "                print(n_labels1, n_labels2)\n",
    "                labels2_offset = labels2 + n_labels1 - 1\n",
    "                labels2_offset[labels2_offset == (n_labels1 - 1)] = 0\n",
    "                labels = labels1 + (labels2_offset)\n",
    "                n_labels = n_labels1 + n_labels2 - 1\n",
    "                stats = np.concatenate((stats1, stats2[1:]), axis=0)\n",
    "                centroids = np.concatenate((centroids1, centroids2[1:]), axis=0)\n",
    "\n",
    "                order = centroids[1:, 0].argsort() + 1\n",
    "                reverse_order = [0 for i in range(len(order) + 1)]\n",
    "                print(order)\n",
    "                print(reverse_order)\n",
    "                for idx, i in enumerate(order):\n",
    "                    reverse_order[i] = idx\n",
    "\n",
    "                keyboard_info = {\n",
    "                    \"top\": top,\n",
    "                    \"bottom\": bottom,\n",
    "                    \"labels\": labels,\n",
    "                    \"centroids\": centroids,\n",
    "                    \"order\": order,\n",
    "                    \"reverse_order\": reverse_order,\n",
    "                    \"stats\": stats\n",
    "                }\n",
    "\n",
    "                if show:\n",
    "                    show_frame(frame)\n",
    "                    show_frame(keyboard)\n",
    "                    show_frame(contour, \"gray\")\n",
    "                    print(f\"number of keys: {n_labels - 1}\")\n",
    "                    show_labels = cv2.cvtColor(labels.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "                    show_labels[labels1 > 0] = 255\n",
    "                    for idx, i in enumerate(order):\n",
    "                        color = (255, 0, 0)\n",
    "                        if i >= n_labels1:\n",
    "                            color = (0, 255, 0)\n",
    "                        show_labels = mark_cross(show_labels, int(centroids[i][0]), int(centroids[i][1]), color=color)\n",
    "                        show_labels = add_text(show_labels, f\"{idx}\", int(centroids[i][0]) - 10, int(centroids[i][1] + 40), color=color)\n",
    "\n",
    "                    show_frame(show_labels)\n",
    "\n",
    "            mp_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "            result = landmarker.detect_for_video(mp_frame, mp.Timestamp.from_seconds(timestamp / 1000).value)\n",
    "            landmark_frame = frame\n",
    "            if result.hand_landmarks:\n",
    "                landmark_frame = draw_landmarks_on_image(frame, result.hand_landmarks)\n",
    "                # show_frame(landmark_frame)\n",
    "\n",
    "            if keyboard_info:\n",
    "                top = keyboard_info[\"top\"]\n",
    "                bottom = keyboard_info[\"bottom\"]\n",
    "                labels = keyboard_info[\"labels\"]\n",
    "                reverse_order = keyboard_info[\"reverse_order\"]\n",
    "                stats = keyboard_info[\"stats\"]\n",
    "\n",
    "                diff1 = get_difference_mask(first_frame[top:bottom, :], frame[top:bottom, :])\n",
    "                cnt1 = np.bincount(labels[diff1 != 0], minlength=np.max(labels) + 1)\n",
    "                diff2 = get_difference_mask(first_frame[top:top + int((bottom - top) * 0.2), :], frame[top:top + int((bottom - top) * 0.2), :])\n",
    "                cnt2 = np.bincount(labels[top:top + int((bottom - top) * 0.2), :][diff2 != 0], minlength=np.max(labels) + 1)\n",
    "\n",
    "                frame = show_labels.copy()\n",
    "                # print(frame.shape)\n",
    "                for i in range(1, len(cnt1)):\n",
    "                    if cnt1[i] / stats[reverse_order[i], 4] > 0.1 and cnt2[i] / stats[reverse_order[i], 4] > 0.011:\n",
    "                        print(f\"hit {reverse_order[i]} key at {timestamp} msec\")\n",
    "                        landmark_frame[top:bottom, :][labels == i] = 255 - (255 - np.array([15, 222, 42], dtype=np.float32) * 0.5 + 255 - landmark_frame[top:bottom, :][labels == i].astype(np.float32) * 0.5).astype(np.uint8)\n",
    "                        show_frame(landmark_frame)\n",
    "\n",
    "                        # print(landmark_frame.shape)\n",
    "                        # print(labels.shape)\n",
    "\n",
    "                        # check_mark = np.all(frame == (255, 0, 0), axis=-1)\n",
    "                        # frame[labels == i] = 255 - (255 - np.array([15, 222, 42], dtype=np.float32) * 0.5 + 255 - frame[labels == i].astype(np.float32) * 0.5).astype(np.uint8)\n",
    "                        # frame[check_mark] = (255, 0, 0)\n",
    "\n",
    "                        # show_frame(landmark_frame)\n",
    "                        # print(f\"{reverse_order[i]}: {cnt1[i] / stats[reverse_order[i], 4] * 100:.2f}%\")\n",
    "                        # print(f\"{reverse_order[i]}: {cnt2[i] / stats[reverse_order[i], 4] * 100:.2f}%\")\n",
    "                #     if cnt1[i] > 300:\n",
    "                #         print(f\"{timestamp}\")\n",
    "                #         print(f\"{reverse_order[i]}: {cnt1[i] / stats[reverse_order[i], 4] * 100:.2f}%\")\n",
    "                #         print(f\"{reverse_order[i]}: {cnt2[i] / stats[reverse_order[i], 4] * 100:.2f}%\")\n",
    "\n",
    "                # if result.hand_landmarks:\n",
    "                #     tmp_frame = landmark_frame.copy()\n",
    "                #     top += 15\n",
    "                #     bottom += 15\n",
    "                #     tmp_frame[top:bottom, :] = frame\n",
    "                #     tmp_frame[:top, :] = (255, 255, 255)\n",
    "                #     tmp_frame[bottom:, :] = (255, 255, 255)\n",
    "                #     frame = draw_landmarks_on_image(tmp_frame, result.hand_landmarks, line_color=(219, 136, 63), circle_color=(131, 83, 41))[top:bottom, :]\n",
    "                    # show_frame(frame)\n",
    "\n",
    "                # show_frame(landmark_frame)\n",
    "                # show_frame(diff1, \"gray\")\n",
    "                # show_frame(diff2, \"gray\")\n",
    "\n",
    "            if saved:\n",
    "                print(f\"timestamp: {timestamp}\")\n",
    "\n",
    "                frame = cv2.cvtColor(landmark_frame, cv2.COLOR_RGB2BGR)\n",
    "                # print(frame.shape)\n",
    "                # frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "                # show_frame(frame)\n",
    "                out.write(frame)\n",
    "\n",
    "        if saved:\n",
    "            print(\"saved output video\")\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
